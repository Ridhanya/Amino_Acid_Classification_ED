{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360d9104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 19:29:24.809985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-04 19:29:25.449737: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-04 19:29:25.449804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-04 19:29:25.449809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.backend import dropout\n",
    "import keras\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a94af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed value\n",
    "seed_value= 3\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. For layers that introduce randomness like dropout, make sure to set seed values \n",
    "# model.add(Dropout(0.25, seed=seed_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed74f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant datasets\n",
    "X_train = pd.read_csv(\"finalXtrain.csv\")\n",
    "y_train = pd.read_csv(\"finalYtrain.csv\")\n",
    "X_test = pd.read_csv(\"finalXtest.csv\")\n",
    "y_test = pd.read_csv(\"finalYtest.csv\")\n",
    "X_val = pd.read_csv(\"finalXval.csv\")\n",
    "y_val = pd.read_csv(\"finalYval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfd6464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 72)\n",
      "(221, 3)\n",
      "(47, 72)\n",
      "(47, 3)\n",
      "(48, 72)\n",
      "(48, 3)\n"
     ]
    }
   ],
   "source": [
    "#check shape\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b5c4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 19:29:26.204708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-04 19:29:26.204758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (VLSI-CAD): /proc/driver/nvidia/version does not exist\n",
      "2024-08-04 19:29:26.206071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "pre_trained_model = load_model('/home/ridhanya/Desktop/AA_PREDICTION/spring24_new_github/ala_arg_fall_oldfiles/alaarg_oct9_check_works3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1279bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 72, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 24, 5)             20        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 5)            20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 24, 5)             0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 12, 5)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 45)             1170      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 45)            180       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 45)             0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 2, 45)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 90)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1820      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,252\n",
      "Trainable params: 3,152\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pre_trained_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2efb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7ff607b6fa30>\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x7ff607a1c310>\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7ff607a1c640>\n",
      "<keras.layers.core.activation.Activation object at 0x7ff607a1d000>\n",
      "<keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7ff607a1d060>\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x7ff607a1d540>\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7ff607a1d6f0>\n",
      "<keras.layers.core.activation.Activation object at 0x7ff607a1e0e0>\n",
      "<keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7ff607a1e140>\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x7ff607a1e680>\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7ff607a1e6b0>\n",
      "<keras.layers.core.dense.Dense object at 0x7ff607a1ec20>\n"
     ]
    }
   ],
   "source": [
    "for layer in pre_trained_model.layers[:-1]:\n",
    "    print(layer)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343ee557",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pre_trained_model.layers[-2].output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fedfd43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# new_output = Dense(3, activation='softmax', name=\"newout\")(x)\n",
    "# x = Dropout(0.5,seed=seed_value)(x)\n",
    "# x = Dense(20,activation ='sigmoid')(x)\n",
    "# x = Dense(10,activation ='sigmoid')(x)\n",
    "# x = Dense(5,activation ='tanh')(x)\n",
    "outputs = Dense(3, activation='softmax', name='predictions')(x)\n",
    "model = Model(inputs=pre_trained_model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77754100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674dbcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 72, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 24, 5)             20        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 5)            20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 24, 5)             0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 12, 5)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 45)             1170      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 45)            180       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 45)             0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 2, 45)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 90)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1820      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,273\n",
      "Trainable params: 63\n",
      "Non-trainable params: 3,210\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef12c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#earlystopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=50)\n",
    "checkpoint_path = 'alaarglys_transferfinallayer_model3.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                   monitor='val_accuracy',\n",
    "                                   save_best_only=True,\n",
    "                                   mode='max',\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bfcfcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/23 [>.............................] - ETA: 10s - loss: 6.8087 - accuracy: 0.1000\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16667, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 5.0202 - accuracy: 0.1448 - val_loss: 1.6575 - val_accuracy: 0.1667\n",
      "Epoch 2/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.7403 - accuracy: 0.3000\n",
      "Epoch 2: val_accuracy improved from 0.16667 to 0.20833, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.6034 - accuracy: 0.1991 - val_loss: 1.5348 - val_accuracy: 0.2083\n",
      "Epoch 3/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 5.2839 - accuracy: 0.1000\n",
      "Epoch 3: val_accuracy improved from 0.20833 to 0.22917, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.5853 - accuracy: 0.1900 - val_loss: 1.4513 - val_accuracy: 0.2292\n",
      "Epoch 4/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.6322 - accuracy: 0.2000\n",
      "Epoch 4: val_accuracy did not improve from 0.22917\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4.4158 - accuracy: 0.1810 - val_loss: 1.4097 - val_accuracy: 0.2292\n",
      "Epoch 5/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6803 - accuracy: 0.4000\n",
      "Epoch 5: val_accuracy improved from 0.22917 to 0.25000, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.2328 - accuracy: 0.1810 - val_loss: 1.3672 - val_accuracy: 0.2500\n",
      "Epoch 6/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6473 - accuracy: 0.4000\n",
      "Epoch 6: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4.2693 - accuracy: 0.2353 - val_loss: 1.3248 - val_accuracy: 0.2292\n",
      "Epoch 7/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.4671 - accuracy: 0.4000\n",
      "Epoch 7: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.9944 - accuracy: 0.2715 - val_loss: 1.2901 - val_accuracy: 0.2292\n",
      "Epoch 8/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.7798 - accuracy: 0.3000\n",
      "Epoch 8: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4.0337 - accuracy: 0.2398 - val_loss: 1.2764 - val_accuracy: 0.2292\n",
      "Epoch 9/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.9864 - accuracy: 0.4000\n",
      "Epoch 9: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4.0477 - accuracy: 0.2670 - val_loss: 1.2676 - val_accuracy: 0.2500\n",
      "Epoch 10/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 5.3721 - accuracy: 0.2000\n",
      "Epoch 10: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.8140 - accuracy: 0.3213 - val_loss: 1.2503 - val_accuracy: 0.2292\n",
      "Epoch 11/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.0183 - accuracy: 0.3000\n",
      "Epoch 11: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.9572 - accuracy: 0.2217 - val_loss: 1.2313 - val_accuracy: 0.2083\n",
      "Epoch 12/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.9237 - accuracy: 0.1000\n",
      "Epoch 12: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.7000 - accuracy: 0.2986 - val_loss: 1.2184 - val_accuracy: 0.2500\n",
      "Epoch 13/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.5769 - accuracy: 0.3000\n",
      "Epoch 13: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.8644 - accuracy: 0.2851 - val_loss: 1.2051 - val_accuracy: 0.2500\n",
      "Epoch 14/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.7807 - accuracy: 0.4000\n",
      "Epoch 14: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.9284 - accuracy: 0.2941 - val_loss: 1.1854 - val_accuracy: 0.2292\n",
      "Epoch 15/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.2844 - accuracy: 0.5000\n",
      "Epoch 15: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.4942 - accuracy: 0.3801 - val_loss: 1.1803 - val_accuracy: 0.2292\n",
      "Epoch 16/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 5.6063 - accuracy: 0.2000\n",
      "Epoch 16: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.6413 - accuracy: 0.3213 - val_loss: 1.1767 - val_accuracy: 0.2292\n",
      "Epoch 17/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.2071 - accuracy: 0.2000\n",
      "Epoch 17: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.5554 - accuracy: 0.3213 - val_loss: 1.1758 - val_accuracy: 0.2083\n",
      "Epoch 18/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.5709 - accuracy: 0.3000\n",
      "Epoch 18: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.6941 - accuracy: 0.2941 - val_loss: 1.1556 - val_accuracy: 0.2292\n",
      "Epoch 19/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0594 - accuracy: 0.3000\n",
      "Epoch 19: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.6422 - accuracy: 0.3484 - val_loss: 1.1574 - val_accuracy: 0.2292\n",
      "Epoch 20/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.5780 - accuracy: 0.4000\n",
      "Epoch 20: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.5308 - accuracy: 0.3665 - val_loss: 1.1539 - val_accuracy: 0.2292\n",
      "Epoch 21/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3613 - accuracy: 0.5000\n",
      "Epoch 21: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.5403 - accuracy: 0.3529 - val_loss: 1.1501 - val_accuracy: 0.2500\n",
      "Epoch 22/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.5796 - accuracy: 0.2000\n",
      "Epoch 22: val_accuracy did not improve from 0.25000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.3765 - accuracy: 0.3665 - val_loss: 1.1527 - val_accuracy: 0.2500\n",
      "Epoch 23/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 5.1611 - accuracy: 0.3000\n",
      "Epoch 23: val_accuracy improved from 0.25000 to 0.27083, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.4579 - accuracy: 0.3801 - val_loss: 1.1448 - val_accuracy: 0.2708\n",
      "Epoch 24/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0602 - accuracy: 0.5000\n",
      "Epoch 24: val_accuracy improved from 0.27083 to 0.29167, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.4869 - accuracy: 0.3801 - val_loss: 1.1365 - val_accuracy: 0.2917\n",
      "Epoch 25/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7314 - accuracy: 0.5000\n",
      "Epoch 25: val_accuracy did not improve from 0.29167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.4776 - accuracy: 0.3575 - val_loss: 1.1505 - val_accuracy: 0.2500\n",
      "Epoch 26/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7103 - accuracy: 0.5000\n",
      "Epoch 26: val_accuracy did not improve from 0.29167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.6832 - accuracy: 0.2986 - val_loss: 1.1386 - val_accuracy: 0.2917\n",
      "Epoch 27/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8098 - accuracy: 0.5000\n",
      "Epoch 27: val_accuracy improved from 0.29167 to 0.31250, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.3998 - accuracy: 0.3801 - val_loss: 1.1354 - val_accuracy: 0.3125\n",
      "Epoch 28/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7370 - accuracy: 0.5000\n",
      "Epoch 28: val_accuracy did not improve from 0.31250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.2032 - accuracy: 0.4027 - val_loss: 1.1359 - val_accuracy: 0.2917\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3967 - accuracy: 0.3000\n",
      "Epoch 29: val_accuracy did not improve from 0.31250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.2336 - accuracy: 0.3756 - val_loss: 1.1535 - val_accuracy: 0.2708\n",
      "Epoch 30/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.2774 - accuracy: 0.2000\n",
      "Epoch 30: val_accuracy did not improve from 0.31250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.4177 - accuracy: 0.3982 - val_loss: 1.1529 - val_accuracy: 0.2708\n",
      "Epoch 31/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6404 - accuracy: 0.4000\n",
      "Epoch 31: val_accuracy did not improve from 0.31250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1709 - accuracy: 0.4796 - val_loss: 1.1352 - val_accuracy: 0.2917\n",
      "Epoch 32/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.5751 - accuracy: 0.2000\n",
      "Epoch 32: val_accuracy did not improve from 0.31250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.3961 - accuracy: 0.3439 - val_loss: 1.1412 - val_accuracy: 0.2708\n",
      "Epoch 33/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4482 - accuracy: 0.4000\n",
      "Epoch 33: val_accuracy did not improve from 0.31250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.3597 - accuracy: 0.3937 - val_loss: 1.1347 - val_accuracy: 0.2917\n",
      "Epoch 34/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8042 - accuracy: 0.5000\n",
      "Epoch 34: val_accuracy improved from 0.31250 to 0.33333, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.2496 - accuracy: 0.4389 - val_loss: 1.1237 - val_accuracy: 0.3333\n",
      "Epoch 35/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0631 - accuracy: 0.2000\n",
      "Epoch 35: val_accuracy improved from 0.33333 to 0.35417, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1904 - accuracy: 0.4344 - val_loss: 1.1144 - val_accuracy: 0.3542\n",
      "Epoch 36/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.1617 - accuracy: 0.2000\n",
      "Epoch 36: val_accuracy improved from 0.35417 to 0.39583, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1895 - accuracy: 0.4299 - val_loss: 1.1085 - val_accuracy: 0.3958\n",
      "Epoch 37/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8171 - accuracy: 0.4000\n",
      "Epoch 37: val_accuracy improved from 0.39583 to 0.41667, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.2897 - accuracy: 0.4344 - val_loss: 1.1034 - val_accuracy: 0.4167\n",
      "Epoch 38/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.8060 - accuracy: 0.5000\n",
      "Epoch 38: val_accuracy did not improve from 0.41667\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.3211 - accuracy: 0.5023 - val_loss: 1.1054 - val_accuracy: 0.3958\n",
      "Epoch 39/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0214 - accuracy: 0.4000\n",
      "Epoch 39: val_accuracy did not improve from 0.41667\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1426 - accuracy: 0.5249 - val_loss: 1.1070 - val_accuracy: 0.3958\n",
      "Epoch 40/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.5782 - accuracy: 0.5000\n",
      "Epoch 40: val_accuracy did not improve from 0.41667\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1788 - accuracy: 0.4706 - val_loss: 1.0989 - val_accuracy: 0.4167\n",
      "Epoch 41/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.7121 - accuracy: 0.4000\n",
      "Epoch 41: val_accuracy improved from 0.41667 to 0.45833, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1039 - accuracy: 0.5158 - val_loss: 1.0920 - val_accuracy: 0.4583\n",
      "Epoch 42/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.9047 - accuracy: 0.6000\n",
      "Epoch 42: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1205 - accuracy: 0.5204 - val_loss: 1.0905 - val_accuracy: 0.4583\n",
      "Epoch 43/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.4903 - accuracy: 0.5000\n",
      "Epoch 43: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1700 - accuracy: 0.4796 - val_loss: 1.0913 - val_accuracy: 0.4583\n",
      "Epoch 44/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0165 - accuracy: 0.8000\n",
      "Epoch 44: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1062 - accuracy: 0.4299 - val_loss: 1.1082 - val_accuracy: 0.3958\n",
      "Epoch 45/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4967 - accuracy: 0.4000\n",
      "Epoch 45: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1499 - accuracy: 0.4796 - val_loss: 1.1008 - val_accuracy: 0.3958\n",
      "Epoch 46/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.7469 - accuracy: 0.2000\n",
      "Epoch 46: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1357 - accuracy: 0.4796 - val_loss: 1.0992 - val_accuracy: 0.4167\n",
      "Epoch 47/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.2342 - accuracy: 0.5000\n",
      "Epoch 47: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1970 - accuracy: 0.4751 - val_loss: 1.0952 - val_accuracy: 0.4167\n",
      "Epoch 48/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6513 - accuracy: 0.3000\n",
      "Epoch 48: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.2217 - accuracy: 0.4706 - val_loss: 1.0920 - val_accuracy: 0.4583\n",
      "Epoch 49/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.9615 - accuracy: 0.5000\n",
      "Epoch 49: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.2566 - accuracy: 0.4887 - val_loss: 1.0921 - val_accuracy: 0.4375\n",
      "Epoch 50/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.5125 - accuracy: 0.4000\n",
      "Epoch 50: val_accuracy did not improve from 0.45833\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1034 - accuracy: 0.5023 - val_loss: 1.0917 - val_accuracy: 0.4375\n",
      "Epoch 51/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3266 - accuracy: 0.5000\n",
      "Epoch 51: val_accuracy improved from 0.45833 to 0.52083, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1986 - accuracy: 0.5113 - val_loss: 1.0840 - val_accuracy: 0.5208\n",
      "Epoch 52/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6837 - accuracy: 0.4000\n",
      "Epoch 52: val_accuracy did not improve from 0.52083\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0523 - accuracy: 0.5385 - val_loss: 1.0977 - val_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6243 - accuracy: 0.6000\n",
      "Epoch 53: val_accuracy did not improve from 0.52083\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0897 - accuracy: 0.4842 - val_loss: 1.0955 - val_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.5137 - accuracy: 0.7000\n",
      "Epoch 54: val_accuracy did not improve from 0.52083\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0235 - accuracy: 0.5520 - val_loss: 1.0904 - val_accuracy: 0.5208\n",
      "Epoch 55/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4204 - accuracy: 0.4000\n",
      "Epoch 55: val_accuracy did not improve from 0.52083\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0185 - accuracy: 0.5204 - val_loss: 1.0904 - val_accuracy: 0.5208\n",
      "Epoch 56/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6401 - accuracy: 0.6000\n",
      "Epoch 56: val_accuracy did not improve from 0.52083\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0306 - accuracy: 0.5430 - val_loss: 1.0808 - val_accuracy: 0.5208\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6784 - accuracy: 0.7000\n",
      "Epoch 57: val_accuracy improved from 0.52083 to 0.54167, saving model to alaarglys_transferfinallayer_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.0458 - accuracy: 0.5747 - val_loss: 1.0804 - val_accuracy: 0.5417\n",
      "Epoch 58/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.6022 - accuracy: 0.2000\n",
      "Epoch 58: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1075 - accuracy: 0.5204 - val_loss: 1.0834 - val_accuracy: 0.5208\n",
      "Epoch 59/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.7242 - accuracy: 0.7000\n",
      "Epoch 59: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9850 - accuracy: 0.5385 - val_loss: 1.0970 - val_accuracy: 0.4792\n",
      "Epoch 60/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3397 - accuracy: 0.6000\n",
      "Epoch 60: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1297 - accuracy: 0.4887 - val_loss: 1.0909 - val_accuracy: 0.5208\n",
      "Epoch 61/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0057 - accuracy: 0.6000\n",
      "Epoch 61: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9986 - accuracy: 0.5204 - val_loss: 1.0882 - val_accuracy: 0.5208\n",
      "Epoch 62/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6389 - accuracy: 0.4000\n",
      "Epoch 62: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0418 - accuracy: 0.5204 - val_loss: 1.0791 - val_accuracy: 0.5417\n",
      "Epoch 63/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.9795 - accuracy: 0.2000\n",
      "Epoch 63: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0687 - accuracy: 0.5204 - val_loss: 1.0896 - val_accuracy: 0.5208\n",
      "Epoch 64/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.8382 - accuracy: 0.7000\n",
      "Epoch 64: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9676 - accuracy: 0.5656 - val_loss: 1.0871 - val_accuracy: 0.5417\n",
      "Epoch 65/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.5460 - accuracy: 0.7000\n",
      "Epoch 65: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9806 - accuracy: 0.5520 - val_loss: 1.0810 - val_accuracy: 0.5417\n",
      "Epoch 66/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8940 - accuracy: 0.7000\n",
      "Epoch 66: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9494 - accuracy: 0.5747 - val_loss: 1.0917 - val_accuracy: 0.5208\n",
      "Epoch 67/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6014 - accuracy: 0.5000\n",
      "Epoch 67: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9935 - accuracy: 0.5566 - val_loss: 1.0924 - val_accuracy: 0.5208\n",
      "Epoch 68/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4090 - accuracy: 0.7000\n",
      "Epoch 68: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8369 - accuracy: 0.5928 - val_loss: 1.0915 - val_accuracy: 0.5208\n",
      "Epoch 69/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.1130 - accuracy: 0.4000\n",
      "Epoch 69: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9830 - accuracy: 0.5113 - val_loss: 1.0860 - val_accuracy: 0.5208\n",
      "Epoch 70/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0647 - accuracy: 0.6000\n",
      "Epoch 70: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9903 - accuracy: 0.5747 - val_loss: 1.0783 - val_accuracy: 0.5208\n",
      "Epoch 71/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.5398 - accuracy: 0.7000\n",
      "Epoch 71: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0220 - accuracy: 0.5747 - val_loss: 1.0770 - val_accuracy: 0.5417\n",
      "Epoch 72/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8000 - accuracy: 0.4000\n",
      "Epoch 72: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9282 - accuracy: 0.5701 - val_loss: 1.0752 - val_accuracy: 0.5417\n",
      "Epoch 73/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0824 - accuracy: 0.6000\n",
      "Epoch 73: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9071 - accuracy: 0.5928 - val_loss: 1.0689 - val_accuracy: 0.5417\n",
      "Epoch 74/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.3120 - accuracy: 1.0000\n",
      "Epoch 74: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9660 - accuracy: 0.5566 - val_loss: 1.0766 - val_accuracy: 0.5208\n",
      "Epoch 75/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.9987 - accuracy: 0.7000\n",
      "Epoch 75: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9958 - accuracy: 0.5385 - val_loss: 1.0858 - val_accuracy: 0.5208\n",
      "Epoch 76/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8941 - accuracy: 0.8000\n",
      "Epoch 76: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8656 - accuracy: 0.5882 - val_loss: 1.0862 - val_accuracy: 0.5208\n",
      "Epoch 77/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.4567 - accuracy: 0.4000\n",
      "Epoch 77: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9653 - accuracy: 0.4977 - val_loss: 1.0878 - val_accuracy: 0.5208\n",
      "Epoch 78/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6896 - accuracy: 0.7000\n",
      "Epoch 78: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8560 - accuracy: 0.6018 - val_loss: 1.0823 - val_accuracy: 0.5208\n",
      "Epoch 79/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.2639 - accuracy: 0.2000\n",
      "Epoch 79: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8731 - accuracy: 0.5430 - val_loss: 1.0827 - val_accuracy: 0.5208\n",
      "Epoch 80/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6640 - accuracy: 0.8000\n",
      "Epoch 80: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0236 - accuracy: 0.5520 - val_loss: 1.0781 - val_accuracy: 0.5417\n",
      "Epoch 81/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.9097 - accuracy: 0.4000\n",
      "Epoch 81: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9000 - accuracy: 0.5747 - val_loss: 1.0777 - val_accuracy: 0.5417\n",
      "Epoch 82/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.1194 - accuracy: 0.7000\n",
      "Epoch 82: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.0163 - accuracy: 0.5973 - val_loss: 1.0718 - val_accuracy: 0.5417\n",
      "Epoch 83/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.1564 - accuracy: 0.5000\n",
      "Epoch 83: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9170 - accuracy: 0.5882 - val_loss: 1.0828 - val_accuracy: 0.5208\n",
      "Epoch 84/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3881 - accuracy: 0.8000\n",
      "Epoch 84: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9606 - accuracy: 0.5882 - val_loss: 1.0912 - val_accuracy: 0.5208\n",
      "Epoch 85/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.1521 - accuracy: 0.5000\n",
      "Epoch 85: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9395 - accuracy: 0.5973 - val_loss: 1.0869 - val_accuracy: 0.5208\n",
      "Epoch 86/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.1671 - accuracy: 0.3000\n",
      "Epoch 86: val_accuracy did not improve from 0.54167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9786 - accuracy: 0.5656 - val_loss: 1.0850 - val_accuracy: 0.5208\n",
      "Epoch 87/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.9630 - accuracy: 0.8000\n",
      "Epoch 87: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8991 - accuracy: 0.5792 - val_loss: 1.0817 - val_accuracy: 0.5417\n",
      "Epoch 88/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.2895 - accuracy: 0.3000\n",
      "Epoch 88: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7890 - accuracy: 0.6154 - val_loss: 1.0837 - val_accuracy: 0.5417\n",
      "Epoch 89/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7692 - accuracy: 0.3000\n",
      "Epoch 89: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9791 - accuracy: 0.5701 - val_loss: 1.0863 - val_accuracy: 0.5417\n",
      "Epoch 90/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7398 - accuracy: 0.6000\n",
      "Epoch 90: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9337 - accuracy: 0.5566 - val_loss: 1.0836 - val_accuracy: 0.5417\n",
      "Epoch 91/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7708 - accuracy: 0.7000\n",
      "Epoch 91: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8242 - accuracy: 0.6380 - val_loss: 1.0772 - val_accuracy: 0.5417\n",
      "Epoch 92/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.4089 - accuracy: 0.4000\n",
      "Epoch 92: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9042 - accuracy: 0.6018 - val_loss: 1.0817 - val_accuracy: 0.5417\n",
      "Epoch 93/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7759 - accuracy: 0.7000\n",
      "Epoch 93: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9030 - accuracy: 0.5837 - val_loss: 1.0825 - val_accuracy: 0.5417\n",
      "Epoch 94/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.7455 - accuracy: 0.9000\n",
      "Epoch 94: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9343 - accuracy: 0.5792 - val_loss: 1.0772 - val_accuracy: 0.5417\n",
      "Epoch 95/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0534 - accuracy: 0.6000\n",
      "Epoch 95: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8322 - accuracy: 0.6244 - val_loss: 1.0804 - val_accuracy: 0.5417\n",
      "Epoch 96/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.2768 - accuracy: 0.5000\n",
      "Epoch 96: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8505 - accuracy: 0.5973 - val_loss: 1.0837 - val_accuracy: 0.5417\n",
      "Epoch 97/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.5907 - accuracy: 0.7000\n",
      "Epoch 97: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8395 - accuracy: 0.6244 - val_loss: 1.0781 - val_accuracy: 0.5417\n",
      "Epoch 98/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.9674 - accuracy: 0.5000\n",
      "Epoch 98: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8083 - accuracy: 0.6018 - val_loss: 1.0815 - val_accuracy: 0.5417\n",
      "Epoch 99/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.0471 - accuracy: 0.5000\n",
      "Epoch 99: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8678 - accuracy: 0.5973 - val_loss: 1.0832 - val_accuracy: 0.5417\n",
      "Epoch 100/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6690 - accuracy: 0.7000\n",
      "Epoch 100: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9978 - accuracy: 0.5520 - val_loss: 1.0801 - val_accuracy: 0.5417\n",
      "Epoch 101/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.7237 - accuracy: 0.8000\n",
      "Epoch 101: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8618 - accuracy: 0.5792 - val_loss: 1.0839 - val_accuracy: 0.5417\n",
      "Epoch 102/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.7242 - accuracy: 0.3000\n",
      "Epoch 102: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8803 - accuracy: 0.5792 - val_loss: 1.0890 - val_accuracy: 0.5208\n",
      "Epoch 103/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3397 - accuracy: 0.7000\n",
      "Epoch 103: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9104 - accuracy: 0.5701 - val_loss: 1.0886 - val_accuracy: 0.5417\n",
      "Epoch 104/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.1944 - accuracy: 0.8000\n",
      "Epoch 104: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9037 - accuracy: 0.5973 - val_loss: 1.0818 - val_accuracy: 0.5417\n",
      "Epoch 105/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8102 - accuracy: 0.7000\n",
      "Epoch 105: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9451 - accuracy: 0.5656 - val_loss: 1.0996 - val_accuracy: 0.5208\n",
      "Epoch 106/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3243 - accuracy: 0.6000\n",
      "Epoch 106: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8941 - accuracy: 0.5656 - val_loss: 1.0893 - val_accuracy: 0.5417\n",
      "Epoch 107/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.5917 - accuracy: 0.7000\n",
      "Epoch 107: val_accuracy did not improve from 0.54167\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8182 - accuracy: 0.5475 - val_loss: 1.0867 - val_accuracy: 0.5417\n",
      "Epoch 107: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "              batch_size=10,\n",
    "              verbose=1,\n",
    "              epochs=500,\n",
    "              validation_data = (X_val,y_val), \n",
    "              callbacks = [es,model_checkpoint]\n",
    "                    ,class_weight = {0:2.4,1:2.23,2:7.37}\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a098600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9486 - accuracy: 0.5957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9485639929771423, 0.5957446694374084]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model('alaarglys_transferfinallayer_model3.h5')\n",
    "model1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a0bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y=model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54d2c689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6       , 0.71428571, 0.16666667])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class-wise accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.to_numpy().argmax(axis=1), y.argmax(axis=1))\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b99c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_Alanine</th>\n",
       "      <th>L_Arginine</th>\n",
       "      <th>L_Lysine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   L_Alanine  L_Arginine  L_Lysine\n",
       "0          0           1         0\n",
       "1          0           1         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e094bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0804 - accuracy: 0.5417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.08035147190094, 0.5416666865348816]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf59ee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9116 - accuracy: 0.6109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9116246104240417, 0.610859751701355]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ridhanya-yolo] *",
   "language": "python",
   "name": "conda-env-ridhanya-yolo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
