{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86170217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 19:08:55.561451: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-04 19:08:56.196272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-04 19:08:56.196342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-04 19:08:56.196347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.backend import dropout\n",
    "import keras\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc998188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed value\n",
    "seed_value= 3\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "# 5. For layers that introduce randomness like dropout, make sure to set seed values \n",
    "# model.add(Dropout(0.25, seed=seed_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcaa9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant datasets\n",
    "X_train = pd.read_csv(\"finalXtrain.csv\")\n",
    "y_train = pd.read_csv(\"finalYtrain.csv\")\n",
    "X_test = pd.read_csv(\"finalXtest.csv\")\n",
    "y_test = pd.read_csv(\"finalYtest.csv\")\n",
    "X_val = pd.read_csv(\"finalXval.csv\")\n",
    "y_val = pd.read_csv(\"finalYval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c978f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 72)\n",
      "(221, 3)\n",
      "(47, 72)\n",
      "(47, 3)\n",
      "(48, 72)\n",
      "(48, 3)\n"
     ]
    }
   ],
   "source": [
    "#check shape\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0066d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "\n",
    "def define_model(seedval):\n",
    "    inputs = tf.keras.Input(shape=(72, 1), name='input')\n",
    "    x = Conv1D(filters=5, kernel_size=3,strides =3)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(tf.keras.activations.relu)(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(2)(x)\n",
    "    x = Conv1D(filters=45, kernel_size=5,strides =2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(tf.keras.activations.relu)(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5,seed=seedval)(x)\n",
    "    x = Dense(20,activation ='relu')(x)\n",
    "#     x = Dropout(0.5,seed=seedval)(x)\n",
    "#     x = Dense(10,activation ='relu')(x)\n",
    "#     x = Dense(5,activation ='relu')(x)\n",
    "    outputs = Dense(3, activation='softmax', name='predictions')(x)\n",
    "    cnn_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer= Adam(), metrics=['accuracy'])\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3ef548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#earlystopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=50)\n",
    "checkpoint_path = 'alaarglys_model3.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                   monitor='val_accuracy',\n",
    "                                   save_best_only=True,\n",
    "                                   mode='max',\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea70f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 72, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 24, 5)             20        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 5)            20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 24, 5)             0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 12, 5)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 45)             1170      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 45)            180       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 45)             0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 2, 45)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 90)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1820      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,273\n",
      "Trainable params: 3,173\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 19:08:56.941924: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-04 19:08:56.941976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (VLSI-CAD): /proc/driver/nvidia/version does not exist\n",
      "2024-08-04 19:08:56.943104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = define_model(seed_value)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783b0079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/23 [>.............................] - ETA: 19s - loss: 6.3770 - accuracy: 0.1000\n",
      "Epoch 1: val_accuracy improved from -inf to 0.43750, saving model to alaarglys_model3.h5\n",
      "23/23 [==============================] - 1s 11ms/step - loss: 4.5582 - accuracy: 0.3665 - val_loss: 1.0840 - val_accuracy: 0.4375\n",
      "Epoch 2/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 6.1550 - accuracy: 0.4000\n",
      "Epoch 2: val_accuracy did not improve from 0.43750\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.9489 - accuracy: 0.3801 - val_loss: 1.1079 - val_accuracy: 0.3333\n",
      "Epoch 3/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.0137 - accuracy: 0.2000\n",
      "Epoch 3: val_accuracy did not improve from 0.43750\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.8072 - accuracy: 0.3982 - val_loss: 1.0953 - val_accuracy: 0.3750\n",
      "Epoch 4/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.8185 - accuracy: 0.6000\n",
      "Epoch 4: val_accuracy did not improve from 0.43750\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.6572 - accuracy: 0.3484 - val_loss: 1.1150 - val_accuracy: 0.2292\n",
      "Epoch 5/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.7860 - accuracy: 0.4000\n",
      "Epoch 5: val_accuracy did not improve from 0.43750\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.5168 - accuracy: 0.4344 - val_loss: 1.0910 - val_accuracy: 0.3542\n",
      "Epoch 6/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.9243 - accuracy: 0.3000\n",
      "Epoch 6: val_accuracy improved from 0.43750 to 0.47917, saving model to alaarglys_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.2978 - accuracy: 0.4796 - val_loss: 1.0652 - val_accuracy: 0.4792\n",
      "Epoch 7/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7540 - accuracy: 0.5000\n",
      "Epoch 7: val_accuracy did not improve from 0.47917\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1943 - accuracy: 0.4887 - val_loss: 1.0619 - val_accuracy: 0.4792\n",
      "Epoch 8/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6436 - accuracy: 0.0000e+00\n",
      "Epoch 8: val_accuracy improved from 0.47917 to 0.50000, saving model to alaarglys_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.1123 - accuracy: 0.4751 - val_loss: 1.0698 - val_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7831 - accuracy: 0.7000\n",
      "Epoch 9: val_accuracy did not improve from 0.50000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.0841 - accuracy: 0.4570 - val_loss: 1.0904 - val_accuracy: 0.4375\n",
      "Epoch 10/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.8296 - accuracy: 0.4000\n",
      "Epoch 10: val_accuracy did not improve from 0.50000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3.0638 - accuracy: 0.4706 - val_loss: 1.0725 - val_accuracy: 0.4375\n",
      "Epoch 11/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.7809 - accuracy: 0.5000\n",
      "Epoch 11: val_accuracy did not improve from 0.50000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9361 - accuracy: 0.4796 - val_loss: 1.0419 - val_accuracy: 0.4792\n",
      "Epoch 12/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7952 - accuracy: 0.4000\n",
      "Epoch 12: val_accuracy did not improve from 0.50000\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.1351 - accuracy: 0.4706 - val_loss: 1.0158 - val_accuracy: 0.4792\n",
      "Epoch 13/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.5954 - accuracy: 0.6000\n",
      "Epoch 13: val_accuracy did not improve from 0.50000\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.9342 - accuracy: 0.4842 - val_loss: 1.0312 - val_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.4385 - accuracy: 0.3000\n",
      "Epoch 14: val_accuracy improved from 0.50000 to 0.56250, saving model to alaarglys_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.9031 - accuracy: 0.5023 - val_loss: 1.0039 - val_accuracy: 0.5625\n",
      "Epoch 15/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.1336 - accuracy: 0.4000\n",
      "Epoch 15: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9760 - accuracy: 0.5158 - val_loss: 0.9986 - val_accuracy: 0.5208\n",
      "Epoch 16/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 5.1332 - accuracy: 0.5000\n",
      "Epoch 16: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7880 - accuracy: 0.5249 - val_loss: 0.9901 - val_accuracy: 0.5625\n",
      "Epoch 17/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.2509 - accuracy: 0.4000\n",
      "Epoch 17: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9594 - accuracy: 0.5158 - val_loss: 0.9888 - val_accuracy: 0.5417\n",
      "Epoch 18/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.5356 - accuracy: 0.5000\n",
      "Epoch 18: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.7575 - accuracy: 0.5928 - val_loss: 0.9872 - val_accuracy: 0.5208\n",
      "Epoch 19/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3207 - accuracy: 0.7000\n",
      "Epoch 19: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7190 - accuracy: 0.5882 - val_loss: 0.9952 - val_accuracy: 0.5417\n",
      "Epoch 20/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.5747 - accuracy: 0.8000\n",
      "Epoch 20: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8602 - accuracy: 0.5204 - val_loss: 0.9989 - val_accuracy: 0.4792\n",
      "Epoch 21/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.1387 - accuracy: 0.5000\n",
      "Epoch 21: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7839 - accuracy: 0.6018 - val_loss: 1.0255 - val_accuracy: 0.4792\n",
      "Epoch 22/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6248 - accuracy: 0.5000\n",
      "Epoch 22: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7680 - accuracy: 0.5520 - val_loss: 1.0333 - val_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 4.5747 - accuracy: 0.2000\n",
      "Epoch 23: val_accuracy did not improve from 0.56250\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7502 - accuracy: 0.5701 - val_loss: 1.0188 - val_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3138 - accuracy: 0.4000\n",
      "Epoch 24: val_accuracy improved from 0.56250 to 0.58333, saving model to alaarglys_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.7403 - accuracy: 0.6244 - val_loss: 1.0164 - val_accuracy: 0.5833\n",
      "Epoch 25/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.2232 - accuracy: 0.7000\n",
      "Epoch 25: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.8029 - accuracy: 0.5747 - val_loss: 1.0197 - val_accuracy: 0.5625\n",
      "Epoch 26/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.5330 - accuracy: 0.6000\n",
      "Epoch 26: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.5847 - accuracy: 0.6244 - val_loss: 0.9940 - val_accuracy: 0.5833\n",
      "Epoch 27/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3685 - accuracy: 0.3000\n",
      "Epoch 27: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6699 - accuracy: 0.5520 - val_loss: 1.0395 - val_accuracy: 0.5625\n",
      "Epoch 28/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.1140 - accuracy: 0.8000\n",
      "Epoch 28: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6265 - accuracy: 0.5520 - val_loss: 1.0827 - val_accuracy: 0.5625\n",
      "Epoch 29/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.7367 - accuracy: 0.8000\n",
      "Epoch 29: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7041 - accuracy: 0.5430 - val_loss: 1.1315 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6293 - accuracy: 0.6000\n",
      "Epoch 30: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.9215 - accuracy: 0.5158 - val_loss: 1.0511 - val_accuracy: 0.5625\n",
      "Epoch 31/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7039 - accuracy: 0.6000\n",
      "Epoch 31: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.5687 - accuracy: 0.6018 - val_loss: 1.0346 - val_accuracy: 0.5625\n",
      "Epoch 32/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.4274 - accuracy: 0.4000\n",
      "Epoch 32: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7594 - accuracy: 0.4977 - val_loss: 1.0710 - val_accuracy: 0.5208\n",
      "Epoch 33/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.0989 - accuracy: 0.9000\n",
      "Epoch 33: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.6692 - accuracy: 0.5339 - val_loss: 1.0697 - val_accuracy: 0.5208\n",
      "Epoch 34/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.5620 - accuracy: 0.8000\n",
      "Epoch 34: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.5354 - accuracy: 0.5792 - val_loss: 1.0546 - val_accuracy: 0.5833\n",
      "Epoch 35/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4411 - accuracy: 0.5000\n",
      "Epoch 35: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6036 - accuracy: 0.6244 - val_loss: 1.0515 - val_accuracy: 0.5833\n",
      "Epoch 36/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.9598 - accuracy: 0.6000\n",
      "Epoch 36: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6210 - accuracy: 0.5837 - val_loss: 1.0879 - val_accuracy: 0.5417\n",
      "Epoch 37/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.6616 - accuracy: 0.8000\n",
      "Epoch 37: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.2644 - accuracy: 0.6652 - val_loss: 1.0861 - val_accuracy: 0.5417\n",
      "Epoch 38/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4925 - accuracy: 0.6000\n",
      "Epoch 38: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.5501 - accuracy: 0.6335 - val_loss: 1.1088 - val_accuracy: 0.5625\n",
      "Epoch 39/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4226 - accuracy: 0.5000\n",
      "Epoch 39: val_accuracy did not improve from 0.58333\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.4300 - accuracy: 0.6109 - val_loss: 1.1393 - val_accuracy: 0.5417\n",
      "Epoch 40/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.7202 - accuracy: 0.7000\n",
      "Epoch 40: val_accuracy improved from 0.58333 to 0.60417, saving model to alaarglys_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.5058 - accuracy: 0.5882 - val_loss: 1.0568 - val_accuracy: 0.6042\n",
      "Epoch 41/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3998 - accuracy: 0.6000\n",
      "Epoch 41: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.3066 - accuracy: 0.6561 - val_loss: 1.0780 - val_accuracy: 0.5833\n",
      "Epoch 42/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.6875 - accuracy: 0.8000\n",
      "Epoch 42: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.4353 - accuracy: 0.6425 - val_loss: 1.0544 - val_accuracy: 0.5833\n",
      "Epoch 43/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3414 - accuracy: 0.6000\n",
      "Epoch 43: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.4684 - accuracy: 0.6244 - val_loss: 1.0737 - val_accuracy: 0.5625\n",
      "Epoch 44/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.4104 - accuracy: 0.8000\n",
      "Epoch 44: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6620 - accuracy: 0.5385 - val_loss: 1.1457 - val_accuracy: 0.5208\n",
      "Epoch 45/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3048 - accuracy: 0.5000\n",
      "Epoch 45: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3437 - accuracy: 0.6199 - val_loss: 1.0833 - val_accuracy: 0.5208\n",
      "Epoch 46/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6377 - accuracy: 0.5000\n",
      "Epoch 46: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.2858 - accuracy: 0.6833 - val_loss: 1.0727 - val_accuracy: 0.5417\n",
      "Epoch 47/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.9614 - accuracy: 0.5000\n",
      "Epoch 47: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.5339 - accuracy: 0.5928 - val_loss: 1.0729 - val_accuracy: 0.5417\n",
      "Epoch 48/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.7649 - accuracy: 0.7000\n",
      "Epoch 48: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.5749 - accuracy: 0.5973 - val_loss: 1.0617 - val_accuracy: 0.5625\n",
      "Epoch 49/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0274 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.4293 - accuracy: 0.6561 - val_loss: 1.0493 - val_accuracy: 0.5833\n",
      "Epoch 50/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.1342 - accuracy: 0.5000\n",
      "Epoch 50: val_accuracy did not improve from 0.60417\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3440 - accuracy: 0.6380 - val_loss: 1.0407 - val_accuracy: 0.5833\n",
      "Epoch 51/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0383 - accuracy: 0.6000\n",
      "Epoch 51: val_accuracy improved from 0.60417 to 0.64583, saving model to alaarglys_model3.h5\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.3549 - accuracy: 0.6380 - val_loss: 1.0487 - val_accuracy: 0.6458\n",
      "Epoch 52/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.9150 - accuracy: 0.5000\n",
      "Epoch 52: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1874 - accuracy: 0.6063 - val_loss: 1.0853 - val_accuracy: 0.6042\n",
      "Epoch 53/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.5753 - accuracy: 1.0000\n",
      "Epoch 53: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1804 - accuracy: 0.6742 - val_loss: 1.0701 - val_accuracy: 0.5625\n",
      "Epoch 54/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.7421 - accuracy: 0.8000\n",
      "Epoch 54: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1907 - accuracy: 0.6742 - val_loss: 1.0634 - val_accuracy: 0.6042\n",
      "Epoch 55/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.7589 - accuracy: 0.8000\n",
      "Epoch 55: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.1637 - accuracy: 0.6380 - val_loss: 1.0566 - val_accuracy: 0.6042\n",
      "Epoch 56/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.9359 - accuracy: 0.7000\n",
      "Epoch 56: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1559 - accuracy: 0.6606 - val_loss: 1.0621 - val_accuracy: 0.5833\n",
      "Epoch 57/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.8428 - accuracy: 0.8000\n",
      "Epoch 57: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.2946 - accuracy: 0.6244 - val_loss: 1.0807 - val_accuracy: 0.5417\n",
      "Epoch 58/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.3987 - accuracy: 0.5000\n",
      "Epoch 58: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2.1027 - accuracy: 0.6833 - val_loss: 1.0907 - val_accuracy: 0.5417\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0227 - accuracy: 0.9000\n",
      "Epoch 59: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1851 - accuracy: 0.6380 - val_loss: 1.1296 - val_accuracy: 0.5208\n",
      "Epoch 60/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.3866 - accuracy: 0.6000\n",
      "Epoch 60: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9321 - accuracy: 0.6878 - val_loss: 1.0880 - val_accuracy: 0.5833\n",
      "Epoch 61/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 3.6607 - accuracy: 0.7000\n",
      "Epoch 61: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0933 - accuracy: 0.6652 - val_loss: 1.0753 - val_accuracy: 0.6250\n",
      "Epoch 62/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.3301 - accuracy: 0.9000\n",
      "Epoch 62: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1052 - accuracy: 0.7149 - val_loss: 1.0924 - val_accuracy: 0.6042\n",
      "Epoch 63/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.4649 - accuracy: 0.7000\n",
      "Epoch 63: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0799 - accuracy: 0.6742 - val_loss: 1.1574 - val_accuracy: 0.5417\n",
      "Epoch 64/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0732 - accuracy: 0.5000\n",
      "Epoch 64: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0558 - accuracy: 0.6697 - val_loss: 1.1171 - val_accuracy: 0.5625\n",
      "Epoch 65/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.8873 - accuracy: 0.7000\n",
      "Epoch 65: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.2991 - accuracy: 0.6380 - val_loss: 1.1207 - val_accuracy: 0.5625\n",
      "Epoch 66/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6127 - accuracy: 0.5000\n",
      "Epoch 66: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1755 - accuracy: 0.6380 - val_loss: 1.1900 - val_accuracy: 0.5208\n",
      "Epoch 67/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0309 - accuracy: 0.7000\n",
      "Epoch 67: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1462 - accuracy: 0.6652 - val_loss: 1.1181 - val_accuracy: 0.5625\n",
      "Epoch 68/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.3100 - accuracy: 0.7000\n",
      "Epoch 68: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.2305 - accuracy: 0.6335 - val_loss: 1.1050 - val_accuracy: 0.5625\n",
      "Epoch 69/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.2268 - accuracy: 0.6000\n",
      "Epoch 69: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9889 - accuracy: 0.6878 - val_loss: 1.1224 - val_accuracy: 0.5625\n",
      "Epoch 70/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.5912 - accuracy: 0.9000\n",
      "Epoch 70: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9373 - accuracy: 0.6833 - val_loss: 1.1153 - val_accuracy: 0.5625\n",
      "Epoch 71/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.3820 - accuracy: 1.0000\n",
      "Epoch 71: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0872 - accuracy: 0.6878 - val_loss: 1.1402 - val_accuracy: 0.5417\n",
      "Epoch 72/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.1956 - accuracy: 0.7000\n",
      "Epoch 72: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8562 - accuracy: 0.7149 - val_loss: 1.1506 - val_accuracy: 0.5417\n",
      "Epoch 73/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1190 - accuracy: 0.9000\n",
      "Epoch 73: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.2139 - accuracy: 0.6833 - val_loss: 1.1796 - val_accuracy: 0.5417\n",
      "Epoch 74/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.2112 - accuracy: 0.8000\n",
      "Epoch 74: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8424 - accuracy: 0.6878 - val_loss: 1.1903 - val_accuracy: 0.5208\n",
      "Epoch 75/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.0492 - accuracy: 0.7000\n",
      "Epoch 75: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0628 - accuracy: 0.6335 - val_loss: 1.2543 - val_accuracy: 0.5208\n",
      "Epoch 76/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.9311 - accuracy: 0.8000\n",
      "Epoch 76: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.7590 - accuracy: 0.7240 - val_loss: 1.2091 - val_accuracy: 0.6250\n",
      "Epoch 77/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3357 - accuracy: 0.8000\n",
      "Epoch 77: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.9347 - accuracy: 0.7149 - val_loss: 1.2227 - val_accuracy: 0.5833\n",
      "Epoch 78/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.2931 - accuracy: 0.9000\n",
      "Epoch 78: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.9945 - accuracy: 0.6968 - val_loss: 1.1609 - val_accuracy: 0.5625\n",
      "Epoch 79/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1127 - accuracy: 0.7000\n",
      "Epoch 79: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.1219 - accuracy: 0.6697 - val_loss: 1.1768 - val_accuracy: 0.5833\n",
      "Epoch 80/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.6294 - accuracy: 0.7000\n",
      "Epoch 80: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0115 - accuracy: 0.6923 - val_loss: 1.1633 - val_accuracy: 0.6250\n",
      "Epoch 81/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.5202 - accuracy: 0.9000\n",
      "Epoch 81: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.7564 - accuracy: 0.7602 - val_loss: 1.1794 - val_accuracy: 0.6042\n",
      "Epoch 82/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1572 - accuracy: 0.9000\n",
      "Epoch 82: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9113 - accuracy: 0.6742 - val_loss: 1.1796 - val_accuracy: 0.5833\n",
      "Epoch 83/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.6105 - accuracy: 0.7000\n",
      "Epoch 83: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8413 - accuracy: 0.7104 - val_loss: 1.2157 - val_accuracy: 0.5833\n",
      "Epoch 84/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.6117 - accuracy: 0.7000\n",
      "Epoch 84: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9839 - accuracy: 0.7240 - val_loss: 1.2056 - val_accuracy: 0.5417\n",
      "Epoch 85/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.7819 - accuracy: 0.8000\n",
      "Epoch 85: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8309 - accuracy: 0.7149 - val_loss: 1.1992 - val_accuracy: 0.5625\n",
      "Epoch 86/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1696 - accuracy: 0.9000\n",
      "Epoch 86: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.7126 - accuracy: 0.7511 - val_loss: 1.2029 - val_accuracy: 0.5625\n",
      "Epoch 87/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.0023 - accuracy: 0.6000\n",
      "Epoch 87: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9625 - accuracy: 0.7014 - val_loss: 1.2096 - val_accuracy: 0.5417\n",
      "Epoch 88/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3167 - accuracy: 0.6000\n",
      "Epoch 88: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.6935 - accuracy: 0.7285 - val_loss: 1.2234 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.9493 - accuracy: 0.5000\n",
      "Epoch 89: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.8976 - accuracy: 0.7104 - val_loss: 1.2285 - val_accuracy: 0.5625\n",
      "Epoch 90/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1913 - accuracy: 0.8000\n",
      "Epoch 90: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6931 - accuracy: 0.7330 - val_loss: 1.2475 - val_accuracy: 0.5833\n",
      "Epoch 91/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.0398 - accuracy: 0.8000\n",
      "Epoch 91: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.7060 - accuracy: 0.7557 - val_loss: 1.2778 - val_accuracy: 0.5625\n",
      "Epoch 92/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.0849 - accuracy: 0.7000\n",
      "Epoch 92: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.5441 - accuracy: 0.7602 - val_loss: 1.2768 - val_accuracy: 0.5625\n",
      "Epoch 93/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.3626 - accuracy: 0.9000\n",
      "Epoch 93: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9032 - accuracy: 0.7240 - val_loss: 1.2703 - val_accuracy: 0.5625\n",
      "Epoch 94/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1167 - accuracy: 0.8000\n",
      "Epoch 94: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.5084 - accuracy: 0.7738 - val_loss: 1.2758 - val_accuracy: 0.5625\n",
      "Epoch 95/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.1415 - accuracy: 0.8000\n",
      "Epoch 95: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8681 - accuracy: 0.7421 - val_loss: 1.2966 - val_accuracy: 0.5208\n",
      "Epoch 96/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.2090 - accuracy: 0.9000\n",
      "Epoch 96: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.8054 - val_loss: 1.2950 - val_accuracy: 0.5208\n",
      "Epoch 97/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 2.2985 - accuracy: 0.8000\n",
      "Epoch 97: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.5643 - accuracy: 0.7738 - val_loss: 1.3110 - val_accuracy: 0.5625\n",
      "Epoch 98/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1944 - accuracy: 1.0000\n",
      "Epoch 98: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.7014 - accuracy: 0.7285 - val_loss: 1.3710 - val_accuracy: 0.5000\n",
      "Epoch 99/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.5600 - accuracy: 1.0000\n",
      "Epoch 99: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6813 - accuracy: 0.7511 - val_loss: 1.3265 - val_accuracy: 0.5000\n",
      "Epoch 100/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.1544 - accuracy: 0.9000\n",
      "Epoch 100: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6782 - accuracy: 0.7647 - val_loss: 1.3271 - val_accuracy: 0.5417\n",
      "Epoch 101/500\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 1.2063 - accuracy: 0.8000\n",
      "Epoch 101: val_accuracy did not improve from 0.64583\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4427 - accuracy: 0.7783 - val_loss: 1.3430 - val_accuracy: 0.5208\n",
      "Epoch 101: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "              batch_size=10,\n",
    "              verbose=1,\n",
    "              epochs=500,\n",
    "              validation_data = (X_val,y_val), \n",
    "              callbacks = [es,model_checkpoint]\n",
    "                    ,class_weight = {0:2.4,1:2.23,2:7.37}\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5828eaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8820 - accuracy: 0.5957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8819532990455627, 0.5957446694374084]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model('alaarglys_model3.h5')\n",
    "model1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "438c666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y=model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b08305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8       , 0.52380952, 0.16666667])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class-wise accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test.to_numpy().argmax(axis=1), y.argmax(axis=1))\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7c7e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0487 - accuracy: 0.6458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0486971139907837, 0.6458333134651184]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac6855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5986 - accuracy: 0.7828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5985991954803467, 0.7828054428100586]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ridhanya-yolo] *",
   "language": "python",
   "name": "conda-env-ridhanya-yolo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
